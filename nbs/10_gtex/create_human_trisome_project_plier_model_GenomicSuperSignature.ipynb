{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34c43a1-10a7-4383-8fd2-1f5f319611f1",
   "metadata": {},
   "source": [
    "# Create Human Trisome Project GenomicSuperSignature model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffecb15-01c0-417d-b161-cd51de34fd45",
   "metadata": {},
   "source": [
    "Marc Subirana-Gran√©s (2024)\n",
    "\n",
    "Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729769e4-0e57-4f40-a4b5-07975a3e6a00",
   "metadata": {},
   "source": [
    "# Load libraries/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88eab2e-d359-4b86-a0a6-945a45fd2203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               _                           \n",
       "platform       x86_64-conda-linux-gnu      \n",
       "arch           x86_64                      \n",
       "os             linux-gnu                   \n",
       "system         x86_64, linux-gnu           \n",
       "status                                     \n",
       "major          4                           \n",
       "minor          3.3                         \n",
       "year           2024                        \n",
       "month          02                          \n",
       "day            29                          \n",
       "svn rev        86002                       \n",
       "language       R                           \n",
       "version.string R version 4.3.3 (2024-02-29)\n",
       "nickname       Angel Food Cake             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>R:</strong> '/home/msubirana/miniconda3/envs/gtex/bin/R'"
      ],
      "text/latex": [
       "\\textbf{R:} '/home/msubirana/miniconda3/envs/gtex/bin/R'"
      ],
      "text/markdown": [
       "**R:** '/home/msubirana/miniconda3/envs/gtex/bin/R'"
      ],
      "text/plain": [
       "                                           R \n",
       "\"/home/msubirana/miniconda3/envs/gtex/bin/R\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.version\n",
    "Sys.which(\"R\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42ce843-a271-4c55-9ec9-3dc2333e626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n",
      "'help(\"repositories\", package = \"BiocManager\")' for details.\n",
      "Replacement repositories:\n",
      "    CRAN: https://cran.r-project.org\n",
      "\n",
      "Bioconductor version 3.18 (BiocManager 1.30.23), R 4.3.3 (2024-02-29)\n",
      "\n",
      "Warning message:\n",
      "\"package(s) not installed when version(s) same as or greater than current; use\n",
      "  `force = TRUE` to re-install: 'EnsDb.Hsapiens.v86'\"\n",
      "Old packages: 'AnnotationHub', 'ape', 'arrow', 'backports', 'beachmat',\n",
      "  'BiocFileCache', 'biomaRt', 'Biostrings', 'brio', 'broom', 'bslib', 'cachem',\n",
      "  'callr', 'clusterProfiler', 'codetools', 'crul', 'curl', 'data.table', 'DBI',\n",
      "  'dbplyr', 'DESeq2', 'digest', 'DOSE', 'emmeans', 'estimability',\n",
      "  'FactoMineR', 'farver', 'fastmap', 'flextable', 'fs', 'future',\n",
      "  'future.apply', 'GenomeInfoDb', 'GenomicAlignments', 'GenomicFeatures',\n",
      "  'ggfun', 'ggraph', 'ggsci', 'ggtree', 'gh', 'GOSemSim', 'graphlayouts',\n",
      "  'gtable', 'hardhat', 'HDF5Array', 'highr', 'htmltools', 'httpuv', 'httr2',\n",
      "  'igraph', 'keras', 'KernSmooth', 'knitr', 'lattice', 'lava', 'lme4', 'minqa',\n",
      "  'munsell', 'mvtnorm', 'nlme', 'officer', 'openssl', 'pkgbuild', 'pkgdown',\n",
      "  'processx', 'promises', 'quantreg', 'ragg', 'RcppArmadillo', 'RcppEigen',\n",
      "  'remotes', 'repr', 'Rhdf5lib', 'Rhtslib', 'rio', 'rlang', 'rmarkdown',\n",
      "  'RSQLite', 'rstudioapi', 'S4Arrays', 'sass', 'scatterpie', 'seriation',\n",
      "  'shape', 'shiny', 'sp', 'SparseArray', 'SparseM', 'stringi', 'survival',\n",
      "  'systemfonts', 'tensorflow', 'testthat', 'textshaping', 'tfruns',\n",
      "  'tidygraph', 'tidyselect', 'tinytex', 'vegan', 'xfun', 'xopen', 'zlibbioc'\n",
      "\n",
      "'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n",
      "'help(\"repositories\", package = \"BiocManager\")' for details.\n",
      "Replacement repositories:\n",
      "    CRAN: https://cran.r-project.org\n",
      "\n",
      "Bioconductor version 3.18 (BiocManager 1.30.23), R 4.3.3 (2024-02-29)\n",
      "\n",
      "Installing package(s) 'EnrichmentBrowser'\n",
      "\n",
      "also installing the dependencies 'annotate', 'graph', 'GSEABase', 'KEGGgraph', 'Rgraphviz', 'SPIA', 'edgeR', 'graphite', 'limma', 'pathview', 'safe'\n",
      "\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Old packages: 'AnnotationHub', 'ape', 'arrow', 'backports', 'beachmat',\n",
      "  'BiocFileCache', 'biomaRt', 'Biostrings', 'brio', 'broom', 'bslib', 'cachem',\n",
      "  'callr', 'clusterProfiler', 'codetools', 'crul', 'curl', 'data.table', 'DBI',\n",
      "  'dbplyr', 'DESeq2', 'digest', 'DOSE', 'emmeans', 'estimability',\n",
      "  'FactoMineR', 'farver', 'fastmap', 'flextable', 'fs', 'future',\n",
      "  'future.apply', 'GenomeInfoDb', 'GenomicAlignments', 'GenomicFeatures',\n",
      "  'ggfun', 'ggraph', 'ggsci', 'ggtree', 'gh', 'GOSemSim', 'graphlayouts',\n",
      "  'gtable', 'hardhat', 'HDF5Array', 'highr', 'htmltools', 'httpuv', 'httr2',\n",
      "  'igraph', 'keras', 'KernSmooth', 'knitr', 'lattice', 'lava', 'lme4', 'minqa',\n",
      "  'munsell', 'mvtnorm', 'nlme', 'officer', 'openssl', 'pkgbuild', 'pkgdown',\n",
      "  'processx', 'promises', 'quantreg', 'ragg', 'RcppArmadillo', 'RcppEigen',\n",
      "  'remotes', 'repr', 'Rhdf5lib', 'Rhtslib', 'rio', 'rlang', 'rmarkdown',\n",
      "  'RSQLite', 'rstudioapi', 'S4Arrays', 'sass', 'scatterpie', 'seriation',\n",
      "  'shape', 'shiny', 'sp', 'SparseArray', 'SparseM', 'stringi', 'survival',\n",
      "  'systemfonts', 'tensorflow', 'testthat', 'textshaping', 'tfruns',\n",
      "  'tidygraph', 'tidyselect', 'tinytex', 'vegan', 'xfun', 'xopen', 'zlibbioc'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BiocManager::install(\"EnsDb.Hsapiens.v86\")\n",
    "BiocManager::install(\"EnrichmentBrowser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e980c935-48f2-4dd5-a7f9-7925bc6e28d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(here)\n",
    "library(GenomicSuperSignature)\n",
    "library(tximport)\n",
    "library(EnsDb.Hsapiens.v86)\n",
    "library(clusterProfiler)\n",
    "library(EnrichmentBrowser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d4bbc-0db2-4a38-b9de-7b56b9cd2f4c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c83c01c-6658-4566-8b5c-e9fe21264711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output nb\n",
    "output_nb_path <-  here('output/nbs/create_human_trisome_project_plier_model_GenomicSuperSignature')\n",
    "\n",
    "dir.create(output_nb_path, showWarnings = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc438802-3f47-4db2-bc4a-ab3972b4b16f",
   "metadata": {},
   "source": [
    "From https://github.com/shbrief/model_building/blob/main/BuildRAVmodel.R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ffa8b25-2bea-4d4f-ad86-2ee41849d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "txdb <- EnsDb.Hsapiens.v86\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635df02-bac1-4320-b00f-af9e608c9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global variable for the whole process\n",
    "main_dir <- \"/mnt/STORE1/16tb_b/refinebio_mice\"\n",
    "in_dir <- file.path(main_dir, \"rna_seq\")\n",
    "out_dir <- file.path(main_dir, \"rna_seq_processed\")\n",
    "wd <- file.path(main_dir, \"mouse_colon\")\n",
    "trainingDatasets <- \"refinebioRseq_mmu_colon\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e0bad-5e2a-48ad-a894-f43edfa64b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec1c0a-849d-40f8-ae1a-734b4db09899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 01_Import\n",
    "studyNames <- c() # study accession numbers as the way it's saved in `in_dir`\n",
    "\n",
    "\n",
    "## 04_Common_Genes\n",
    "cutoff <- 0.9  # Percent top varying genes to include in RAVmodel\n",
    "\n",
    "## 05_PCA\n",
    "n <- 20   # The number PCs to keep\n",
    "\n",
    "## 06_Clustering\n",
    "library(factoextra)\n",
    "d <- 2.25  # for cluster number (line 56)\n",
    "note <- \"29 mouse colon studies\"\n",
    "annotGeneSets <- \"MSigDB_mmu_C2\"\n",
    "\n",
    "## 07_Final_Model\n",
    "\n",
    "org <- \"mmu\"\n",
    "db <- \"msigdb\"\n",
    "cat <- \"C2\"\n",
    "\n",
    "##### 01_Import ################################################################\n",
    "## Create directories\n",
    "if (!dir.exists(out_dir)) {dir.create(out_dir)}\n",
    "if (!dir.exists(wd)) {dir.create(wd)}\n",
    "\n",
    "## Prepare tx2gene file for tximport\n",
    "k <- AnnotationDbi::keys(txdb, keytype = \"TXNAME\")\n",
    "tx2gene <- AnnotationDbi::select(txdb, k, \"SYMBOL\", \"TXNAME\")\n",
    "tx2gene <- tx2gene[,1:2]\n",
    "tx2gene <- tx2gene[!is.na(tx2gene$SYMBOL),]\n",
    "\n",
    "## Save combined expression matrix of each study\n",
    "for (studyName in studyNames) {\n",
    "\n",
    "    ## collect all the samples\n",
    "    dir_path <- file.path(in_dir, studyName)\n",
    "    files <- list.files(dir_path)   # all the files in the folder\n",
    "    files <- files[grepl(\"_quant.sf\", files)]   # only quant.sf files\n",
    "    files <- file.path(dir_path, files)\n",
    "    names(files) <- gsub(\"_quant.sf\", \"\", basename(files))   # assign names\n",
    "\n",
    "    out_path <- file.path(out_dir, studyName)\n",
    "    if (!dir.exists(out_path)) {dir.create(out_path)}\n",
    "\n",
    "    tryCatch({\n",
    "        ## tximport\n",
    "        rseq_counts <- tximport(files = files,\n",
    "                                type = \"salmon\",\n",
    "                                tx2gene = tx2gene,\n",
    "                                countsFromAbundance = \"lengthScaledTPM\")\n",
    "        fname <- paste0(studyName, \".rds\")\n",
    "        saveRDS(rseq_counts, file = file.path(out_path, fname))\n",
    "    }, error = function(e) {\n",
    "        ## studies with an error during import\n",
    "        study_with_error <- data.frame(studyName, conditionMessage(e))\n",
    "        write.table(study_with_error,\n",
    "                    file = file.path(wd, \"studies_with_error.tsv\"),\n",
    "                    append = TRUE, row.names = FALSE, col.names = FALSE)\n",
    "    })\n",
    "}\n",
    "\n",
    "\n",
    "##### 02_Filtering #############################################################\n",
    "## Update the available study with successful tximport\n",
    "import_error <- read.table(file.path(wd, \"studies_with_error.tsv\"))\n",
    "studyNames <- studyNames[!studyNames %in% import_error[,1]]\n",
    "\n",
    "## Log2 transformation\n",
    "for (studyName in studyNames) {\n",
    "    dir_path <- file.path(out_dir, studyName)\n",
    "    file.path <- file.path(dir_path, paste0(studyName, \".rds\"))\n",
    "    countMatrix <- readRDS(file.path)\n",
    "\n",
    "    # log2(TPM+1) transformation\n",
    "    count <- countMatrix$counts\n",
    "    count <- log2(count + 1)\n",
    "\n",
    "    # Save the results for each studyName in `_count.csv`\n",
    "    write.table(count, file.path(dir_path, paste0(studyName, \"_count.csv\")))\n",
    "\n",
    "    # Standard output to check the progress\n",
    "    filteringDone <- paste(\"Successful Filtering done :\", studyName)\n",
    "    print(filteringDone)\n",
    "}\n",
    "\n",
    "\n",
    "##### 03_Top_Genes #############################################################\n",
    "## List containing the ordered list of genes from each study\n",
    "topGenesInTrainingData <- vector(mode = \"list\", \n",
    "                                 length = length(studyNames)) \n",
    "\n",
    "for (studyName in studyNames) {\n",
    "    dir_path <- file.path(out_dir, studyName)\n",
    "    x <- data.table::fread(file.path(dir_path, paste0(studyName, \"_count.csv\")), \n",
    "                           showProgress = FALSE)\n",
    "    \n",
    "    # order by standard deviation\n",
    "    y <- apply(x[,-1], 1, sd) \n",
    "    names(y) <- x$V1\n",
    "    y <- y[order(y, decreasing = TRUE)]\n",
    "    \n",
    "    topGenesInTrainingData[[studyName]] <- y\n",
    "    rm(x)\n",
    "}\n",
    "\n",
    "print(paste(\"Finish collecting top\", cutoff*100, \"% varying genes from\", \n",
    "            length(studyNames), \"studies.\"))  #--> Standard output\n",
    "\n",
    "## Save\n",
    "fname <- paste0(\"topGenesInTrainingData_\", Sys.Date(), \".rds\")\n",
    "saveRDS(topGenesInTrainingData, file.path(wd, fname))\n",
    "\n",
    "\n",
    "##### 04_Common_Genes ##########################################################\n",
    "topGenes <- c()\n",
    "\n",
    "k <- length(topGenesInTrainingData[[1]])\n",
    "k <- round(k*cutoff)\n",
    "topGenes <- names(topGenesInTrainingData[[1]])[1:k]\n",
    "\n",
    "for (i in 2:length(topGenesInTrainingData)) {\n",
    "    l <- length(topGenesInTrainingData[[i]])\n",
    "    l <- round(l*cutoff)\n",
    "    ls <- list(topGenes, names(topGenesInTrainingData[[i]])[1:l])\n",
    "    topGenes <- Reduce(intersect, ls)\n",
    "}\n",
    "\n",
    "topGenes <- topGenes[nzchar(topGenes)] # remove empty character\n",
    "saveRDS(topGenes, file.path(wd, paste0(\"topGenes_\", length(topGenes),\".rds\")))\n",
    "\n",
    "\n",
    "##### 05_PCA ###################################################################\n",
    "## An empty list for PCA results (rotation and variance)\n",
    "trainingData_PCA <- vector(\"list\", length(studyNames))\n",
    "names(trainingData_PCA) <- studyNames\n",
    "\n",
    "## Calculate sd and mean across all the samples\n",
    "allSamples <- data.frame(matrix(NA, nrow = length(cg), ncol = 0)) \n",
    "rownames(allSamples) <- cg\n",
    "iter <- 0\n",
    "\n",
    "for (studyName in studyNames) {\n",
    "    file_path <- file.path(out_dir, studyName)\n",
    "    x <- data.table::fread(file.path(file_path, paste0(studyName, \"_count.csv\")), \n",
    "                           showProgress = FALSE)\n",
    "    x <- data.frame(x[,-1], row.names = x$V1)\n",
    "    iter <- iter + 1\n",
    "    allSamples <- cbind(allSamples, x[cg,])\n",
    "}\n",
    "\n",
    "print(paste(\"Calculate standard deviation and mean of\", iter, \"studies.\"))\n",
    "s <- apply(allSamples, 1, sd)\n",
    "m <- apply(allSamples, 1, mean)\n",
    "SdMean <- list(sd = s, mean = m)\n",
    "\n",
    "saveRDS(SdMean, file.path(wd, paste0(trainingDatasets, \"_SdMean.rds\"))) # sd and mean\n",
    "saveRDS(allSamples, file.path(wd, paste0(trainingDatasets, \".rds\"))) # matrix containing all samples\n",
    "\n",
    "## Remove non-expressing genes in all samples (m == 0)\n",
    "non_exp <- which(s == 0) %>% names\n",
    "s <- s[!names(s) %in% non_exp]\n",
    "m <- m[!names(m) %in% non_exp]\n",
    "\n",
    "##### PCA\n",
    "for (studyName in studyNames) {\n",
    "    file_path <- file.path(out_dir, studyName)\n",
    "    x <- data.table::fread(file.path(file_path, paste0(studyName, \"_count.csv\")), \n",
    "                           showProgress = FALSE)\n",
    "    x <- data.frame(x[,-1], row.names = x$V1)\n",
    "    x <- x[cg,,drop=FALSE]\n",
    "    \n",
    "    # Remove non-expressing genes in all samples (m == 0)\n",
    "    x <- x[!rownames(x) %in% non_exp,]\n",
    "    \n",
    "    # This part will be used if any sample is removed upon filtering\n",
    "    if (ncol(x) <= 20) {\n",
    "        final_sample_number <- paste(ncol(x), \"samples after filtering.\")\n",
    "        study_with_less_samples <- data.frame(studyName, final_sample_number)\n",
    "        write.table(study_with_less_samples, \n",
    "                    file = file.path(wd, \"study_with_less_samples.tsv\"),\n",
    "                    append = TRUE, row.names = FALSE, col.names = FALSE)\n",
    "        \n",
    "        print(paste(studyName, \"has only\", ncol(x), \"samples after filtering.\"))\n",
    "        next\n",
    "    }\n",
    "    \n",
    "    # Normalization\n",
    "    x <- sweep(x, 1, m)\n",
    "    x <- sweep(x, 1, s, \"/\")\n",
    "    # x <- preprocessCore::normalize.quantiles(x)   # quantile normalization\n",
    "    \n",
    "    # PCA\n",
    "    pca_res <- prcomp(t(x))   # x is a matrix with genes(row) x samples(column)\n",
    "    trainingData_PCA[[studyName]]$rotation <- pca_res$rotation[,1:n]\n",
    "    colnames(trainingData_PCA[[studyName]]$rotation) <- paste0(studyName, \".PC\", c(1:n))\n",
    "    eigs <- pca_res$sdev^2\n",
    "    pca_summary <- rbind(SD = sqrt(eigs),\n",
    "                         Variance = eigs/sum(eigs),\n",
    "                         Cumulative = cumsum(eigs)/sum(eigs))\n",
    "    trainingData_PCA[[studyName]]$variance <- pca_summary[,1:n]\n",
    "    colnames(trainingData_PCA[[studyName]]$variance) <- paste0(studyName, \".PC\", c(1:n))\n",
    "    \n",
    "    rm(x)\n",
    "}\n",
    "\n",
    "## Update studyNames after PCA\n",
    "too_few_samples <- read.table(file.path(wd, \"study_with_less_samples.tsv\"))\n",
    "studyNames <- studyNames[!studyNames %in% too_few_samples[,1]]\n",
    "\n",
    "## Remove empty trainingData_PCA\n",
    "trainingData_PCA <- trainingData_PCA[names(trainingData_PCA) %in% studyNames]\n",
    "\n",
    "## Save\n",
    "fname <- paste0(trainingDatasets, \"_PCs_rowNorm.rds\")\n",
    "saveRDS(trainingData_PCA, file.path(wd, fname))\n",
    "\n",
    "\n",
    "##### 06_Clustering ############################################################\n",
    "## Combine all PCs\n",
    "allZ_list <- lapply(trainingData_PCA, function(x) x$rotation)\n",
    "allZ <- Reduce(cbind, allZ_list)\n",
    "all <- t(allZ)   # a matrix of PCs (row) x genes (column)\n",
    "print(paste(\"Dimension of allZ is\", dim(allZ))) \n",
    "saveRDS(allZ, file.path(wd, \"allZ.rds\"))\n",
    "\n",
    "##### Hierarchical Clustering\n",
    "## Calculate distance\n",
    "start <- Sys.time()\n",
    "res.dist <- factoextra::get_dist(all, method = \"spearman\")\n",
    "end <- Sys.time()\n",
    "t <- end - start\n",
    "print(paste(t, \"took to calculate distance.\"))  \n",
    "saveRDS(res.dist, file.path(wd, \"res_dist.rds\"))\n",
    "\n",
    "## Cut the tree\n",
    "k <- round(nrow(all)/d, 0)\n",
    "start <- Sys.time()\n",
    "res.hcut <- factoextra::hcut(res.dist, k = k, hc_func = \"hclust\", \n",
    "                             hc_method = \"ward.D\", hc_metric = \"spearman\")\n",
    "end <- Sys.time()\n",
    "t2 <- end - start\n",
    "print(paste(round(t2, 2), \"seconds took to cut tree.\"))   \n",
    "saveRDS(res.hcut, file.path(wd, \"res_hcut.rds\"))\n",
    "\n",
    "\n",
    "##### Build avgLoading \n",
    "trainingData_PCclusters <- buildAvgLoading(allZ, k, cluster = res.hcut$cluster)\n",
    "\n",
    "## Silhouette Width\n",
    "cl <- trainingData_PCclusters$cluster\n",
    "silh_res <- cluster::silhouette(cl, res.dist)\n",
    "cl_silh_width <- summary(silh_res)$clus.avg.widths\n",
    "trainingData_PCclusters$sw <- cl_silh_width  # add silhouette width to the result\n",
    "\n",
    "## Save\n",
    "fname <- paste0(trainingDatasets, \"_PCclusters.rds\")\n",
    "saveRDS(trainingData_PCclusters, file.path(wd, fname))\n",
    "\n",
    "\n",
    "##### 07_Final_Model ###########################################################\n",
    "## Variance Explained from PCA result \n",
    "pca_summary <- list()\n",
    "for (i in seq_along(trainingData_PCA)) {\n",
    "    pca_summary[[i]] <- trainingData_PCA[[i]]$variance\n",
    "    names(pca_summary)[i] <- names(trainingData_PCA)[i]\n",
    "}\n",
    "\n",
    "##### MeSH terms \n",
    "dat_dir <- \"~/GSS/GenomicSuperSignaturePaper/inst/extdata\" #--> Save in GCP bucket\n",
    "json_path <- file.path(dat_dir, \"sra_to_mesh-000000000000.json\") \n",
    "x <- jsonlite::stream_in(file(json_path))\n",
    "mesh_table <- x[x$identifier %in% studyNames,]\n",
    "\n",
    "len <- length(studyNames)\n",
    "save(mesh_table, \n",
    "     file = file.path(wd, paste0(\"MeSH_terms_\", len, \"refinebio.rda\")))\n",
    "\n",
    "## Create bagOfWords and MeSH_freq\n",
    "MeSH_freq <- table(mesh_table$name) %>% \n",
    "    sort(., decreasing = TRUE)  # frequency of each term\n",
    "for (i in seq_len(nrow(mesh_table))) { \n",
    "    mesh_table$bagOfWords[i] <- MeSH_freq[mesh_table$name[i]]\n",
    "} # add frequency to the main table \n",
    "\n",
    "unique_id <- unique(mesh_table$identifier)\n",
    "\n",
    "## Split MeSH term table to a list of each study, `all_MeSH`\n",
    "all_MeSH <- vector(\"list\", length(unique_id))\n",
    "names(all_MeSH) <- unique_id\n",
    "for (study in unique_id) {\n",
    "    ind <- grepl(study, mesh_table$identifier)\n",
    "    mesh_meta <- c(\"score\", \"identifier\", \"concept\", \"name\",\n",
    "                   \"explanation\", \"bagOfWords\") # Currently excludes 'concept'\n",
    "    all_MeSH[[study]] <- mesh_table[ind, mesh_meta]\n",
    "}\n",
    "\n",
    "## In case MeSH term information is not available for all the studies\n",
    "trainingData_MeSH <- all_MeSH[studyNames] # Subset only to the studies used in the model\n",
    "\n",
    "##### Build PCAGenomicSignatures object\n",
    "## Assemble training data\n",
    "trainDat <- as.data.frame(matrix(nrow = length(pca_summary), ncol = 0))\n",
    "trainDat$PCAsummary <- pca_summary\n",
    "row.names(trainDat) <- names(pca_summary)\n",
    "\n",
    "RAVindex <- as.matrix(trainingData_PCclusters$avgLoading)\n",
    "colnames(RAVindex) <- paste0(\"RAV\", seq_len(ncol(RAVindex)))\n",
    "\n",
    "## Construct RAVmodel\n",
    "RAVmodel <- PCAGenomicSignatures(assays = list(RAVindex = RAVindex), \n",
    "                                 trainingData = DataFrame(trainDat))\n",
    "\n",
    "## metadata\n",
    "metadata(RAVmodel) <- trainingData_PCclusters[c(\"cluster\", \"size\", \"k\", \"n\")]\n",
    "names(metadata(RAVmodel)$size) <- paste0(\"RAV\", seq_len(ncol(RAVmodel)))\n",
    "geneSets(RAVmodel) <- annotGeneSets\n",
    "metadata(RAVmodel)$MeSH_freq <- MeSH_freq\n",
    "updateNote(RAVmodel) <- note\n",
    "metadata(RAVmodel)$version <- \"0.1.0\"\n",
    "\n",
    "## colData\n",
    "colData(RAVmodel)$RAV <- paste0(\"RAV\", seq_len(ncol(RAVmodel)))\n",
    "studies(RAVmodel) <- trainingData_PCclusters$studies\n",
    "silhouetteWidth(RAVmodel) <- trainingData_PCclusters$sw\n",
    "\n",
    "## trainingData\n",
    "mesh(RAVmodel) <- trainingData_MeSH[rownames(trainingData(RAVmodel))]\n",
    "\n",
    "## Save pre-GSEA version\n",
    "fname <- paste0(trainingDatasets, \"_RAVmodel_\", \n",
    "                format(Sys.Date(), format=\"%Y%m%d\"), \".rds\")\n",
    "saveRDS(RAVmodel, file.path(wd, fname))\n",
    "\n",
    "\n",
    "##### GSEA #####################################################################\n",
    "gsea_dir <- file.path(wd, paste0(\"gsea_\", annotGeneSets))\n",
    "if(!dir.exists(gsea_dir)) {dir.create(gsea_dir)}\n",
    "\n",
    "gs <- EnrichmentBrowser::getGenesets(org = org, \n",
    "                                     db = db, \n",
    "                                     cat = cat, # category \n",
    "                                     gene.id.type = \"SYMBOL\")\n",
    "term2gene <- stack(gs)\n",
    "colnames(term2gene) <- c(\"entrez_gene\", \"gs_name\")\n",
    "term2gene <- term2gene[,c(2,1)] # the order of columns should be term and gene.\n",
    "\n",
    "## From `model_building/inst/scripts/build_gsea_DB.R` script\n",
    "for (i in seq_len(ncol(RAVmodel))) {\n",
    "    fname <- paste0(\"gsea_\", i, \".rds\")\n",
    "    fpath <- file.path(gsea_dir, fname)\n",
    "    \n",
    "    geneList <- RAVindex(RAVmodel)[,i]\n",
    "    geneList <- sort(geneList, decreasing = TRUE)\n",
    "    res <- clusterProfiler::GSEA(geneList, TERM2GENE = term2gene,\n",
    "                                 pvalueCutoff = 0.05, seed = TRUE)\n",
    "    saveRDS(res, fpath)\n",
    "}\n",
    "\n",
    "## Load searchPathways function\n",
    "func_path <- system.file(\"scripts/searchPathways.R\", package = \"GenomicSuperSignature\")\n",
    "source(func_path)\n",
    "\n",
    "gsea_all <- searchPathways(RAVmodel, gsea_dir)  \n",
    "gsea(RAVmodel) <- gsea_all\n",
    "\n",
    "## Save post-GSEA version\n",
    "fname <- paste0(trainingDatasets, \"_RAVmodel_\", annotGeneSets, \n",
    "                \"_\", format(Sys.Date(), format=\"%Y%m%d\"),\".rds\")\n",
    "saveRDS(RAVmodel, file.path(wd, fname))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all,-execution,-papermill,-trusted",
   "notebook_metadata_filter": "-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
